Witajcie w drugim odcinku podcastu "Marek AI". W poprzednim odcinku omówiliśmy podstawy: czym jest sztuczna inteligencja, jej historię i rodzaje. Dzisiaj zagłębimy się w temat, który jest sercem i silnikiem współczesnej AI – uczenie maszynowe, czyli machine learning.

Czym dokładnie jest uczenie maszynowe? Najprościej mówiąc, jest to poddziedzina sztucznej inteligencji, która daje komputerom zdolność do uczenia się bez bycia wprost zaprogramowanym. Zamiast pisać sztywne reguły, dostarczamy algorytmowi ogromne ilości danych i pozwalamy mu samodzielnie znaleźć w nich wzorce, zależności i na tej podstawie podejmować decyzje lub robić przewidywania.

To fundamentalna zmiana w podejściu. Zamiast mówić maszynie "jak" coś zrobić, pokazujemy jej "co" ma osiągnąć na podstawie przykładów. To trochę jak uczenie dziecka rozpoznawania zwierząt. Nie opisujemy mu precyzyjnie, że kot ma cztery łapy, futro i ogon, ale pokazujemy mu setki zdjęć kotów, mówiąc "to jest kot". Po pewnym czasie dziecko samo zaczyna rozpoznawać koty, nawet te, których nigdy wcześniej nie widziało. Podobnie działają algorytmy uczenia maszynowego.

Istnieją trzy główne paradygmaty, czyli sposoby uczenia maszynowego. Są to: uczenie nadzorowane, uczenie nienadzorowane oraz uczenie przez wzmacnianie. Omówmy każdy z nich.

Pierwszy i najpopularniejszy to uczenie nadzorowane (supervised learning). W tym podejściu "nadzór" polega na tym, że dostarczamy algorytmowi dane, które są już opisane, czyli "oetykietowane". Każdy przykład w zbiorze danych ma przypisaną prawidłową odpowiedź. Celem algorytmu jest nauczenie się reguły, która potrafi mapować dane wejściowe na prawidłowe odpowiedzi.

Uczenie nadzorowane dzieli się na dwa główne typy zadań: klasyfikację i regresję.
Klasyfikacja polega na przypisaniu danych do jednej z predefiniowanych kategorii. Na przykład, uczymy model rozpoznawania spamu, dając mu tysiące e-maili z etykietą "spam" lub "nie spam". Po treningu model potrafi sam zaklasyfikować nowe, nieznane wiadomości. Inne przykłady to rozpoznawanie, czy na zdjęciu jest kot, czy pies, albo diagnozowanie chorób na podstawie objawów.
Regresja z kolei polega na przewidywaniu wartości ciągłej, czyli liczby. Na przykład, na podstawie danych o mieszkaniach, takich jak metraż, lokalizacja i liczba pokoi, model może przewidzieć jego cenę. Inne przykłady to prognozowanie pogody, przewidywanie kursu akcji czy szacowanie czasu dostawy.

Drugi paradygmat to uczenie nienadzorowane (unsupervised learning). Tutaj sytuacja jest zupełnie inna. Dostarczamy algorytmowi dane, które nie mają żadnych etykiet. Nie mówimy mu, co jest prawidłową odpowiedzią. Zadaniem modelu jest samodzielne odkrycie ukrytej struktury, wzorców i zależności w tych danych.

Najpopularniejsze zadania w uczeniu nienadzorowanym to klastrowanie i asocjacja.
Klastrowanie, czyli grupowanie, polega na podzieleniu danych na grupy, w których obiekty są do siebie podobne, a jednocześnie różnią się od obiektów w innych grupach. Wyobraźmy sobie, że mamy dane o klientach sklepu. Algorytm klastrujący może samodzielnie podzielić ich na segmenty, na przykład "oszczędni studenci", "rodziny z dziećmi" czy "zamożni seniorzy", co pozwala na lepsze dopasowanie oferty marketingowej.
Asocjacja to odkrywanie reguł współwystępowania. Klasycznym przykładem jest analiza koszyków zakupowych w supermarkecie. Algorytm może odkryć regułę, że klienci, którzy kupują pieluchy, często kupują również piwo. Taka wiedza może być wykorzystana do optymalizacji rozmieszczenia produktów na półkach.

I wreszcie trzeci paradygmat: uczenie przez wzmacnianie (reinforcement learning). Ten rodzaj uczenia jest inspirowany psychologią behawioralną i przypomina tresurę zwierząt. Mamy tu "agenta", który działa w pewnym "środowisku". Agent wykonuje akcje, a za każdą z nich otrzymuje od środowiska "nagrodę" lub "karę". Celem agenta jest nauczenie się takiej strategii działania, czyli "polityki", która maksymalizuje sumę otrzymanych nagród w czasie.

Uczenie przez wzmacnianie świetnie sprawdza się w sytuacjach, gdzie trzeba podejmować sekwencje decyzji. To właśnie dzięki tej technice powstały programy, które pokonały mistrzów świata w szachach czy Go. Agent uczył się gry, rozgrywając miliony partii sam ze sobą i otrzymując nagrodę za wygraną, a karę za przegraną. Inne zastosowania to sterowanie robotami, optymalizacja systemów logistycznych czy zarządzanie zasobami.

Na koniec warto podkreślić jedną, niezwykle ważną rzecz. Niezależnie od tego, o którym paradygmacie uczenia mówimy, fundamentem zawsze są dane. Jakość, ilość i różnorodność danych treningowych ma absolutnie kluczowe znaczenie dla skuteczności każdego modelu uczenia maszynowego. Zasada "garbage in, garbage out" (śmieci na wejściu, śmieci na wyjściu) jest tu święta. Nawet najlepszy algorytm nie stworzy dobrego modelu, jeśli będzie uczony na złych, niekompletnych lub stronniczych danych.

Podsumowując, dzisiaj dowiedzieliśmy się, że uczenie maszynowe to serce współczesnej AI, polegające na automatycznym odkrywaniu wzorców w danych. Poznaliśmy trzy główne paradygmaty: uczenie nadzorowane, gdzie uczymy na oznaczonych przykładach; uczenie nienadzorowane, gdzie algorytm sam szuka struktury w danych; oraz uczenie przez wzmacnianie, oparte na systemie nagród i kar.

To wszystko w tym odcinku. W następnym przyjrzymy się bliżej konkretnej, niezwykle popularnej dziś architekturze modeli AI – wielkim modelom językowym, znanym jako LLM. Dziękuję za wysłuchanie i do usłyszenia!
